{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('arrow_sstable': conda)"
  },
  "interpreter": {
   "hash": "11e14a7450b1aa7dac7c67def91465b11df4befdfc2edcec9501702ae1b0749a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 3. Cassandra to Arrow\n",
    "\n",
    "We use some code from the Cassandra server to read the SSTable, but instead of de/serializing to/from CQL, we use an [Arrow IPC stream](http://arrow.apache.org/), which is stored in a columnar format and better suited for analytics.\n",
    "\n",
    "Data transformations:\n",
    "\n",
    "1. SSTable on disk\n",
    "2. Deserialized into Java Object in C* server\n",
    "3. Client makes request to server (not to C* DB)\n",
    "4. Data serialized via Arrow IPC stream\n",
    "5. Sent across network\n",
    "6. Arrow IPC stream received by client\n",
    "7. Transformed into Arrow Table / cuDF\n",
    "\n",
    "**Pros:**\n",
    "- doesn't make request to the main Cassandra DB, which lessens the load and allows for other operations to run\n",
    "- less de/serialization involved using the Arrow IPC stream\n",
    "\n",
    "**Cons:**\n",
    "- don't want to have to start Cassandra or use the JVM\n",
    "- complex architecture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "HOST = '127.0.0.1'\n",
    "PORT = 9143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bytes(sock, n):\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        more = sock.recv(n - len(data))\n",
    "        if not more:\n",
    "            raise EOFError(\"Socket connection ended before reading specified number of bytes\")\n",
    "        data += more\n",
    "    return data\n",
    "\n",
    "def read_u8(sock):\n",
    "    data = read_bytes(sock, 8)\n",
    "    return int.from_bytes(data, byteorder='big')\n",
    "\n",
    "# read data from socket\n",
    "def fetch_data():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "        sock.connect((HOST, PORT))\n",
    "        sock.sendall(b'hello world\\n')\n",
    "        num_tables = read_u8(sock)\n",
    "        table_buffers = []\n",
    "        for i in range(num_tables):\n",
    "            print('receiving table', i)\n",
    "            table_size = read_u8(sock)\n",
    "            buf = read_bytes(sock, table_size)\n",
    "            table_buffers.append(buf)\n",
    "    return table_buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "receiving table 0\nreceiving table 1\nparsing table 0\n  partition key       liveness_info_tstamp  item_count   last_update_timestamp\n0          uiop 2021-07-19 17:11:39.401960          32 2021-07-19 17:11:39.403\n1          qwer 2021-07-19 17:11:05.241304         246 2021-07-19 17:11:05.243\n2          abcd 2021-07-19 17:10:50.190249          12 2021-07-19 17:10:50.192\n3          1234 2021-07-19 17:10:39.050207           5 2021-07-19 17:10:39.052\n4          9876 2021-07-19 17:10:38.041705           2 2021-07-19 17:10:38.047\nparsing table 1\nEmpty DataFrame\nColumns: [partition key, liveness_info_tstamp]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "buffers = fetch_data()\n",
    "for i, buf in enumerate(buffers):\n",
    "    if i > 0:\n",
    "        print()\n",
    "    print('parsing table', i)\n",
    "    reader = pa.ipc.open_stream(buf)\n",
    "    arrow_table = reader.read_all()\n",
    "    print(arrow_table.to_pandas()) # for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CMakeCache.txt          deletion_time.h         sstable_statistics.cpp\n\u001b[1m\u001b[36mCMakeFiles\u001b[m\u001b[m              results.json            sstable_statistics.h\nCPackConfig.cmake       rules.ninja             sstable_summary.cpp\nCPackSourceConfig.cmake sstable_data.cpp        sstable_summary.h\nbuild.ninja             sstable_data.h          \u001b[31msstable_to_arrow\u001b[m\u001b[m\ncmake_install.cmake     sstable_index.cpp       table.parquet\ndeletion_time.cpp       sstable_index.h\n"
     ]
    }
   ],
   "source": [
    "!ls ../cpp/build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_table = pd.read_parquet(\"../cpp/build/table.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  _timestamp                                      partition key  \\\n",
       "0 1924-04-12  {'org.apache.cassandra.db.marshal.UUIDType': b...   \n",
       "\n",
       "  clustering key                                               data  \\\n",
       "0     1970-01-01   vulputate. Vestibulum at imperdiet metus, et ...   \n",
       "\n",
       "   sensor_value                                         station_id  \n",
       "0     97.651955  b'(\\xdfc\\xb7\\xccWC\\xcb\\x97R\\xfa\\xe6\\x9d\\x16S\\xda'  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_timestamp</th>\n      <th>partition key</th>\n      <th>clustering key</th>\n      <th>data</th>\n      <th>sensor_value</th>\n      <th>station_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1924-04-12</td>\n      <td>{'org.apache.cassandra.db.marshal.UUIDType': b...</td>\n      <td>1970-01-01</td>\n      <td>vulputate. Vestibulum at imperdiet metus, et ...</td>\n      <td>97.651955</td>\n      <td>b'(\\xdfc\\xb7\\xccWC\\xcb\\x97R\\xfa\\xe6\\x9d\\x16S\\xda'</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "parquet_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
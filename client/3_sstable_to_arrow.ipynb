{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 4. SSTable to Arrow\n",
    "\n",
    "We manually read the SSTables on disk using [Kaitai Struct](https://kaitai.io/) and then send it to the client analytics program through an Arrow IPC stream.\n",
    "\n",
    "Data transformations:\n",
    "\n",
    "1. SSTable on disk\n",
    "2. Deserialized into Kaitai object in C++\n",
    "3. Client makes request to server (not to C* DB)\n",
    "4. Kaitai object serialized via Arrow IPC stream\n",
    "5. Sent across network\n",
    "6. Arrow IPC stream received by client\n",
    "7. Transformed into Arrow Table / cuDF\n",
    "\n",
    "**Pros:**\n",
    "- doesn't make request to C* DB, which lessens the load and allows for other operations to run\n",
    "- Kaitai Struct format is almost self-documenting and easier to maintain (e.g. for DSE SSTable format)\n",
    "    - can also generate cool images by exporting to graphviz:\n",
    "    - ![](assets/data.png)\n",
    "    - ![](assets/statistics.png)\n",
    "    - ![](assets/index.png)\n",
    "    - ![](assets/summary.png)\n",
    "- works especially well with serverless since most of the files are all in one place\n",
    "- more flexible for future developments like parallelization with CUDA\n",
    "\n",
    "~~Cons~~"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "import pyarrow as pa\n",
    "#from blazingsql import BlazingContext\n",
    "import cudf\n",
    "import cupy\n",
    "from cuml.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np # for visualization purposes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap # dunno how to use the RAPIDS equivalent of this yet\n",
    "\n",
    "HOST = '127.0.0.1'\n",
    "PORT = 9143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from socket\n",
    "def fetch_data():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.connect((HOST, PORT))\n",
    "        s.sendall(b'hello world\\n')\n",
    "        data = b''\n",
    "        while True:\n",
    "            newdata = s.recv(1024)\n",
    "            if not newdata:\n",
    "                break\n",
    "            data += newdata\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = fetch_data()\n",
    "reader = pa.ipc.open_stream(buffer)\n",
    "table = reader.read_all()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = cudf.DataFrame.from_arrow(table)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BlazingContext()\n",
    "bc.create_table(\"classes\", gdf)\n",
    "bc.describe_table(\"classes\")\n",
    "result = bc.sql(\"SELECT * FROM classes\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "\n",
    "# we only take the first two features. We could avoid this ugly\n",
    "# slicing by using a two-dim dataset\n",
    "X = gdf.iloc[:, :2]\n",
    "y = gdf.iloc[:, 2]\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "cmap_bold = ['darkorange', 'c', 'darkblue']\n",
    "\n",
    "weights = 'uniform'\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf = KNeighborsClassifier(n_neighbors=15)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
    "y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
    "xx, yy = cupy.meshgrid(cupy.arange(x_min, x_max, h),\n",
    "                        cupy.arange(y_min, y_max, h))\n",
    "Z = clf.predict(cupy.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx.get(), yy.get(), Z.get(), cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "sns.scatterplot(x=X.iloc[:, 0].to_array(), y=X.iloc[:, 1].to_array(), hue=np.array(['setosa', 'versicolor', 'virginica'])[y.to_array()],\n",
    "                palette=cmap_bold, alpha=1.0, edgecolor=\"black\")\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "            % (n_neighbors, weights))\n",
    "\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "\n",
    "plt.show()"
   ]
  }
 ]
}
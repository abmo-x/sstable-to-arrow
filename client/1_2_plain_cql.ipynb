{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('arrow_sstable': conda)"
  },
  "interpreter": {
   "hash": "11e14a7450b1aa7dac7c67def91465b11df4befdfc2edcec9501702ae1b0749a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. CQL to cuDF\n",
    "\n",
    "## (a) via `pandas`\n",
    "\n",
    "**Pros:**\n",
    "- already implemented, convenient\n",
    "\n",
    "**Cons:**\n",
    "- makes request to C* DB, taking computation power\n",
    "- \"unnecessary\" data transformations on client side"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from blazingsql import BlazingContext\n",
    "import cudf\n",
    "\n",
    "import config"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# connect to the Cassandra server in the cloud and configure the session settings\n",
    "cloud_config= {\n",
    "        'secure_connect_bundle': '/home/ubuntu/secure-connect-clitest.zip'\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider(config.username, config.password)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect('clitest')\n",
    "session.default_fetch_size = 1e7"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def pandas_factory(colnames, rows):\n",
    "    \"\"\"Read the data returned by the driver into a pandas DataFrame\"\"\"\n",
    "    return pd.DataFrame(rows, columns=colnames)\n",
    "session.row_factory = pandas_factory\n",
    "\n",
    "# run the CQL query and get the data\n",
    "result_set = session.execute(\"select * from clitest.chipotle_stores limit 100;\")\n",
    "df = result_set._current_rows\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create a new dataframe with the same data, but stored on the GPU\n",
    "gdf = cudf.DataFrame.from_pandas(df)\n",
    "gdf[\"latitude\"] = gdf[\"latitude\"].astype(\"double\")\n",
    "gdf[\"longitude\"] = gdf[\"longitude\"].astype(\"double\")\n",
    "gdf.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# BlazingSQL helps us speed up SQL queries using the GPU\n",
    "bc = BlazingContext(initial_pool_size=1.0486e+10)\n",
    "bc.create_table(\"cql_table\", gdf)\n",
    "bc.describe_table(\"cql_table\")\n",
    "result = bc.sql(\"select * from cql_table\")\n",
    "result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (b) via `pyarrow`\n",
    "\n",
    "This approach is almost identical, but transforms the data from the driver\n",
    "into a pyarrow Table (which lives on the GPU and can be easily transformed\n",
    "into a cuDF DataFrame) rather than a pandas DataFrame.\n",
    "\n",
    "**Pros:**\n",
    "- cleans up some transformations on client side\n",
    "\n",
    "**Cons:**\n",
    "- still makes request to Cassandra server, taking computation power\n",
    "\n",
    "In the following block of code, we replace the `pandas_factory` fn from the previous example, which returns a pandas DataFrame, with `row_factory`, which returns a pyarrow Table."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def getcol(col):\n",
    "    rtn = pa.array(col)\n",
    "    # This is a sample type conversion. For a full implementation,\n",
    "    # you'd need to fully check which arrow types need to be manually casted for compatibility with cuDF\n",
    "    if pa.types.is_decimal(rtn.type):\n",
    "        return rtn.cast('float32')\n",
    "    return rtn\n",
    "\n",
    "def row_factory(colnames, rows):\n",
    "    # is there a faster way to do this zip operation?\n",
    "    # essentially we just need to convert from the row format passed by\n",
    "    # CQL into the column format of arrow\n",
    "    cols = [getcol(col) for col in zip(*rows)]\n",
    "    table = pa.table({ colnames[i]: cols[i] for i in range(len(colnames)) })\n",
    "    return table\n",
    "\n",
    "session.row_factory = row_factory\n",
    "result_set = session.execute(\"SELECT * FROM clitest.chipotle_stores LIMIT 100;\")\n",
    "df = result_set.current_rows\n",
    "print(df)\n",
    "gdf = cudf.DataFrame.from_arrow(df)\n",
    "\n",
    "# then go up and run the above cells using gdf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from cassandra.cluster import Cluster"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster = Cluster()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "session = cluster.connect('baselines')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rows = session.execute('SELECT * FROM iot')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for row in rows:\n",
    "    print(row)"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}